{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Create a CSV file to write the data\n",
    "# csv_file = open(\"tripadvisor_reviews.csv\", \"w\", newline='', encoding=\"utf-8\")\n",
    "csv_file = open(\"lagos_hotels.csv\", \"w\", newline='', encoding=\"utf-8\")\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "# Initialize the web driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Define the URL of the TripAdvisor page\n",
    "base_url = \"https://www.tripadvisor.com\"\n",
    "url = \"https://www.tripadvisor.com/Hotels-g304026-Lagos_Lagos_State-Hotels.html\"\n",
    "driver.get(url)\n",
    "\n",
    "# Get the page source\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "current_url = driver.current_url\n",
    "\n",
    "# Function to extract review details\n",
    "def extract_review_details(review_div):\n",
    "    # Extract the review title\n",
    "    review_title = review_div.find('div', class_='KgQgP MC _S b S6 H5 _a')\n",
    "    title = review_title.text.strip() if review_title else None\n",
    "\n",
    "    # Extract the review text\n",
    "    review_text_div = review_div.find('span', class_='QewHA H4 _a')\n",
    "    review_text = review_text_div.select_one(':first-child').text.strip() if review_text_div else None\n",
    "\n",
    "    # Extract the stay date\n",
    "    stay_date_span = review_div.find('span', class_='usajM')\n",
    "    stay_date = stay_date_span.next_sibling.strip() if stay_date_span else None\n",
    "\n",
    "    # Extract the trip type\n",
    "    trip_type_span = review_div.find('span', class_='trip_type_label')\n",
    "    trip_type = trip_type_span.next_sibling.strip() if trip_type_span else None\n",
    "\n",
    "    # Extract the room tips\n",
    "    room_tip_div = review_div.find('span', class_='tkWaG b')\n",
    "    room_tip = room_tip_div.find_next_sibling('span').text if room_tip_div else None\n",
    "\n",
    "    # Extract Review Date\n",
    "    review_date_div = review_div.find('a', class_='ui_header_link uyyBf')\n",
    "    author_info = review_date_div.next_sibling.strip() if review_date_div else None\n",
    "\n",
    "    # Extract location of author\n",
    "    location_div = review_div.find('span', class_='ui_icon map-pin-fill fXexN')\n",
    "    author_location = location_div.next_sibling.strip() if location_div else None\n",
    "\n",
    "    # Extract helpful votes, contributions, and review author\n",
    "    author_div = review_div.find('div', class_='MziKN')\n",
    "    elements = [span.text for span in author_div.select('span.phMBo > span')] if author_div else None\n",
    "\n",
    "    # Extract the overall review rating\n",
    "    rating_div = review_div.find('div', class_='Hlmiy F1')\n",
    "    rating_span = rating_div.find('span', class_='ui_bubble_rating')\n",
    "    rating_class = rating_span['class'][1].replace('bubble_', '') if rating_span else None\n",
    "\n",
    "    # Extract the specific review rating\n",
    "    rating_div = review_div.find_all('div', class_='hemdC S2 H2 WWOoy')\n",
    "    specific_ratings = []\n",
    "    for specific_rating in rating_div:\n",
    "        value1 = specific_rating.find('span', class_='Nd').find_next_sibling().text\n",
    "        value2 = specific_rating.find('span', class_='Nd').select_one(':first-child')['class'][1]\n",
    "        specific_ratings.append(f\"{value1} {value2}\")\n",
    "\n",
    "    # Create a dictionary to store all the extracted details\n",
    "    review_details = {\n",
    "        \"Review Title\": title,\n",
    "        \"Review Text\": review_text,\n",
    "        \"Stay Date\": stay_date,\n",
    "        \"Trip Type\": trip_type,\n",
    "        \"Room Tips\": room_tip,\n",
    "        \"Review Date\": author_info,\n",
    "        \"Author Location\": author_location,\n",
    "        \"Author Info\": elements,\n",
    "        \"Overall Rating\": rating_class,\n",
    "        \"Specific Ratings\": specific_ratings,\n",
    "    }\n",
    "\n",
    "    # Create a list with the extracted details\n",
    "    details_list = [\n",
    "        title, review_text, stay_date, trip_type, room_tip,\n",
    "        author_info, author_location, ', '.join(elements),\n",
    "        rating_class, ', '.join(specific_ratings)\n",
    "    ]\n",
    "\n",
    "    # Write the details to the CSV file\n",
    "    csv_writer.writerow(details_list)\n",
    "\n",
    "    return review_details\n",
    "\n",
    "# Function to loop through pages for reviews\n",
    "def get_page_reviews(soup, counter):\n",
    "    # Find and extract review details\n",
    "    reviews = soup.find('div', class_='uNacK PS')\n",
    "    if reviews:\n",
    "        review_divs = reviews.find_all('div', class_='YibKl MC R2 Gi z Z BB pBbQr')\n",
    "        for count, review_div in enumerate(review_divs, 1):\n",
    "            print(f\"----------- Review {counter} -----------\")\n",
    "            counter += 1\n",
    "            details = extract_review_details(review_div)\n",
    "            for key, value in details.items():\n",
    "                if value:\n",
    "                    print(f\"{key}: {value}\")\n",
    "\n",
    "# Add a hotel to the list\n",
    "def add_hotel(hotel_list: list, unique_hotel_names: set, hotel_name: str , hotel_url: str):\n",
    "    if hotel_name not in unique_hotel_names or hotel_name == \"NIL\":\n",
    "        # If the hotel name is unique, add it to the list and update the set\n",
    "        hotel_info = {'name': hotel_name.strip(), 'url': hotel_url.strip()}\n",
    "        hotel_list.append(hotel_info)\n",
    "        unique_hotel_names.add(hotel_name)\n",
    "\n",
    "# Get Reviews for hotel\n",
    "def get_hotel_reviews(hotel):\n",
    "    driver.get(hotel['url'])\n",
    "\n",
    "    # Get the page source\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    current_url = driver.current_url\n",
    "    counter = 1\n",
    "\n",
    "    page = 1\n",
    "    print('-----------')\n",
    "    print(f\"Hotel Name: {hotel['name']}\")\n",
    "    print('-----------')\n",
    "    print(f\"----------- Review {page} -----------\")\n",
    "    print('-----------')\n",
    "\n",
    "    get_page_reviews(soup, counter)\n",
    "    \n",
    "    # Loop to navigate to the next page\n",
    "    while True:\n",
    "        # Click the \"Next\" button to load the next page\n",
    "        next_button = driver.find_element(By.CLASS_NAME, 'ui_button.nav.next.primary ')\n",
    "        \n",
    "        # If there's a \"Next\" button, click it to go to the next page\n",
    "        if next_button:\n",
    "            # Check if the \"Next\" button is disabled\n",
    "            is_disabled = \"disabled\" in next_button.get_attribute(\"class\")\n",
    "            \n",
    "            # If the \"Next\" button is disabled, break out of the loop\n",
    "            if is_disabled:\n",
    "                break        \n",
    "        else:\n",
    "            break\n",
    "\n",
    "        next_button.click()\n",
    "        \n",
    "        # Wait for the next page to load by checking the URL change\n",
    "        WebDriverWait(driver, 10).until(EC.url_changes(current_url))\n",
    "        \n",
    "        # Wait for 2 secs for page to be loaded, it can be adjusted based on your internet speed\n",
    "        time.sleep(2)\n",
    "\n",
    "        page += 1\n",
    "\n",
    "        print('-----------')\n",
    "        print(f\"----------- Page {page} -----------\")\n",
    "        print('-----------')\n",
    "\n",
    "        # Get the updated page source\n",
    "        html = driver.page_source\n",
    "\n",
    "        # Parse the new page with BeautifulSoup\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        current_url = driver.current_url\n",
    "\n",
    "        get_page_reviews(soup, counter)\n",
    "\n",
    "# List to hold found hotels\n",
    "hotel_list = []\n",
    "\n",
    "# Track hotel names\n",
    "unique_hotel_names = set()\n",
    "\n",
    "# check for the See All button and Click\n",
    "time.sleep(5)\n",
    "see_all_button = driver.find_element(By.CLASS_NAME, 'rmyCe._G')\n",
    "if see_all_button:\n",
    "    see_all_button.click()\n",
    "\n",
    "    # Wait for 5 secs for page to be loaded, it can be adjusted based on your internet speed\n",
    "    time.sleep(2)\n",
    "\n",
    "    html = driver.page_source\n",
    "    # Parse the HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Wait for the page to load up more content checking if the next symbol is loaded\n",
    "    # WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CLASS_NAME, 'xkSty')))  \n",
    "    time.sleep(2)  \n",
    "\n",
    "# get all links to hotels, store in a list\n",
    "hotel_links = soup.find_all('a', class_='BMQDV _F Gv wSSLS SwZTJ FGwzt ukgoS')\n",
    "for hotel_link in hotel_links:\n",
    "    hotel_url = base_url + hotel_link['href']\n",
    "    h3_tag = hotel_link.find('h3') # find the first h3 tag in the html\n",
    "    if h3_tag:\n",
    "        text_value = h3_tag.text\n",
    "        text_list = text_value.split('.', 1)\n",
    "        if len(text_list) == 1:\n",
    "            continue\n",
    "        hotel_name = text_list[-1].strip()\n",
    "        add_hotel(hotel_list, unique_hotel_names, hotel_name, hotel_url)\n",
    "\n",
    "# loop thru the list and get review for hotels\n",
    "# for hotel in hotel_list:\n",
    "#     print(f\"{hotel['name']}, {hotel['url']}\")\n",
    "csv_writer.writerow(hotel_links)\n",
    "\n",
    "while True:    \n",
    "    hotel_list = []\n",
    "\n",
    "    # Click the \"Next\" button to load the next page\n",
    "    next_button = driver.find_element(By.CLASS_NAME, 'BrOJk.u.j.z._F.wSSLS.tIqAi.unMkR')\n",
    "    \n",
    "    # If there's a \"Next\" button, click it to go to the next page\n",
    "    if next_button:\n",
    "        next_button.click()    \n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    # Wait for the next page to load by checking the URL change\n",
    "    WebDriverWait(driver, 10).until(EC.url_changes(current_url))\n",
    "    \n",
    "    # Wait for 2 secs for page to be loaded, it can be adjusted based on your internet speed\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Get the updated page source\n",
    "    html = driver.page_source\n",
    "\n",
    "    # Parse the new page with BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    current_url = driver.current_url\n",
    "\n",
    "    # check for the See All button and Click\n",
    "    see_all_button = driver.find_element(By.CLASS_NAME, 'rmyCe._G')\n",
    "    if see_all_button:\n",
    "        see_all_button.click()\n",
    "\n",
    "        # Wait for 5 secs for page to be loaded, it can be adjusted based on your internet speed\n",
    "        time.sleep(5)\n",
    "\n",
    "        html = driver.page_source\n",
    "        # Parse the HTML with BeautifulSoup\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        # Wait for the page to load up more content checking if the next symbol is loaded\n",
    "        # WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CLASS_NAME, 'xkSty')))\n",
    "        time.sleep(2)    \n",
    "\n",
    "    # get all links to hotels, store in a list\n",
    "    hotel_links = soup.find_all('a', class_='BMQDV _F Gv wSSLS SwZTJ FGwzt ukgoS')\n",
    "    for hotel_link in hotel_links:\n",
    "        hotel_url = base_url + hotel_link['href']\n",
    "        h3_tag = hotel_link.find('h3') # find the first h3 tag in the html\n",
    "        if h3_tag:\n",
    "            text_value = h3_tag.text\n",
    "            text_list = text_value.split('.', 1)\n",
    "            if len(text_list) == 1:\n",
    "                continue\n",
    "            hotel_name = text_list[-1].strip()\n",
    "            add_hotel(hotel_list, unique_hotel_names, hotel_name, hotel_url)\n",
    "\n",
    "    # loop thru the list and get review for hotels\n",
    "    # for hotel in hotel_list:\n",
    "    #     print(f\"{hotel['name']}, {hotel['url']}\")\n",
    "    \n",
    "    csv_writer.writerow(hotel_list)\n",
    "\n",
    "    if len(hotel_links) > 100:\n",
    "        break\n",
    "\n",
    "\n",
    "# loop thru the hotel list to get the reviews\n",
    "# for hotel in hotel_list:\n",
    "#     get_hotel_reviews(hotel)\n",
    "\n",
    "# Close the CSV file\n",
    "csv_file.close()\n",
    "\n",
    "# Close the web driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the web driver\n",
    "driver = webdriver.Chrome()\n",
    "hotel_count = 1\n",
    "# Function to extract review details\n",
    "def extract_review_details(review_div):\n",
    "    # Extract the review title\n",
    "    review_title = review_div.find('div', class_='KgQgP MC _S b S6 H5 _a')\n",
    "    title = review_title.text.strip() if review_title else None\n",
    "\n",
    "    # Extract the review text\n",
    "    review_text_div = review_div.find('span', class_='QewHA H4 _a')\n",
    "    review_text = review_text_div.select_one(':first-child').text.strip() if review_text_div else None\n",
    "\n",
    "    # Extract the stay date\n",
    "    stay_date_span = review_div.find('span', class_='usajM')\n",
    "    stay_date = stay_date_span.next_sibling.strip() if stay_date_span else None\n",
    "\n",
    "    # Extract the trip type\n",
    "    trip_type_span = review_div.find('span', class_='trip_type_label')\n",
    "    trip_type = trip_type_span.next_sibling.strip() if trip_type_span else None\n",
    "\n",
    "    # Extract the room tips\n",
    "    room_tip_div = review_div.find('span', class_='tkWaG b')\n",
    "    room_tip = room_tip_div.find_next_sibling('span').text if room_tip_div else None\n",
    "\n",
    "    # Extract Review Date\n",
    "    review_date_div = review_div.find('a', class_='ui_header_link uyyBf')\n",
    "    author_info = review_date_div.next_sibling.strip() if review_date_div else None\n",
    "\n",
    "    # Extract location of author\n",
    "    location_div = review_div.find('span', class_='ui_icon map-pin-fill fXexN')\n",
    "    author_location = location_div.next_sibling.strip() if location_div else None\n",
    "\n",
    "    # Extract helpful votes, contributions, and review author\n",
    "    author_div = review_div.find('div', class_='MziKN')\n",
    "    elements: list = [span.text for span in author_div.select('span.phMBo > span')] if author_div else []\n",
    "\n",
    "    # Extract the overall review rating\n",
    "    rating_div = review_div.find('div', class_='Hlmiy F1')\n",
    "    rating_span = rating_div.find('span', class_='ui_bubble_rating')\n",
    "    rating_class = rating_span['class'][1].replace('bubble_', '') if rating_span else None\n",
    "\n",
    "    # Extract the specific review rating\n",
    "    rating_div = review_div.find_all('div', class_='hemdC S2 H2 WWOoy')\n",
    "    specific_ratings = []\n",
    "    for specific_rating in rating_div:\n",
    "        value1 = specific_rating.find('span', class_='Nd').find_next_sibling().text\n",
    "        value2 = specific_rating.find('span', class_='Nd').select_one(':first-child')['class'][1]\n",
    "        specific_ratings.append(f\"{value1} {value2}\")\n",
    "\n",
    "    # Create a dictionary to store all the extracted details\n",
    "    review_details = {\n",
    "        \"Review Title\": title,\n",
    "        \"Review Text\": review_text,\n",
    "        \"Stay Date\": stay_date,\n",
    "        \"Trip Type\": trip_type,\n",
    "        \"Room Tips\": room_tip,\n",
    "        \"Review Date\": author_info,\n",
    "        \"Author Location\": author_location,\n",
    "        \"Author Info\": elements,\n",
    "        \"Overall Rating\": rating_class,\n",
    "        \"Specific Ratings\": specific_ratings,\n",
    "    }\n",
    "\n",
    "    return review_details\n",
    "\n",
    "# Function to loop through pages for reviews\n",
    "def get_page_reviews(soup):\n",
    "    # Find and extract review details\n",
    "    page_reviews = []\n",
    "    reviews = soup.find('div', class_='uNacK PS')\n",
    "    if reviews:\n",
    "        review_divs = reviews.find_all('div', class_='YibKl MC R2 Gi z Z BB pBbQr')\n",
    "        for count, review_div in enumerate(review_divs, 1):\n",
    "            page_reviews.append(extract_review_details(review_div))\n",
    "    \n",
    "    return page_reviews\n",
    "\n",
    "# Get Reviews for hotel\n",
    "def get_hotel_reviews(hotel):\n",
    "    driver.get(hotel[1])\n",
    "    driver.maximize_window()\n",
    "\n",
    "    # Get the page source\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    current_url = driver.current_url\n",
    "    counter = 1\n",
    "\n",
    "    # Get number of reviews\n",
    "    no_of_reviews = soup.find('span', class_='biGQs _P pZUbB KxBGd')\n",
    "    no_of_reviews = no_of_reviews.text.strip() if no_of_reviews else 0\n",
    "\n",
    "    page = 1\n",
    "    print('-----------')\n",
    "    print(f\"Hotel {hotel_count}: {hotel[0]} : {no_of_reviews}\")\n",
    "    print('-----------')\n",
    "\n",
    "    data = get_page_reviews(soup)\n",
    "    df = pd.DataFrame(data)\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(f\"{hotel[0]}.csv\", mode='a', index=False)\n",
    "\n",
    "    # Loop to navigate to the next page\n",
    "    while True:\n",
    "        # Click the \"Next\" button to load the next page\n",
    "        next_button = driver.find_elements(By.CLASS_NAME, 'ui_button.nav.next.primary ')\n",
    "        \n",
    "        # If there's a \"Next\" button, click it to go to the next page\n",
    "        if len(next_button) > 0 and next_button[0]:\n",
    "            # Check if the \"Next\" button is disabled\n",
    "            attributes = next_button[0].get_attribute(\"class\")\n",
    "            if attributes is not None and \"disabled\" in attributes:\n",
    "                is_disabled = True\n",
    "            else:\n",
    "                is_disabled = False\n",
    "\n",
    "            # If the \"Next\" button is disabled, break out of the loop\n",
    "            if is_disabled:\n",
    "                break        \n",
    "        else:\n",
    "            print(f'No next button in {hotel[0]}')\n",
    "            break\n",
    "\n",
    "        next_button[0].click()\n",
    "        \n",
    "        # Wait for the next page to load by checking the URL change\n",
    "        WebDriverWait(driver, 20).until(EC.url_changes(current_url))\n",
    "        \n",
    "        # Wait for 2 secs for page to be loaded, it can be adjusted based on your internet speed\n",
    "        time.sleep(2)\n",
    "\n",
    "        page += 1\n",
    "\n",
    "        # Get the updated page source\n",
    "        html = driver.page_source\n",
    "\n",
    "        # Parse the new page with BeautifulSoup\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        current_url = driver.current_url\n",
    "\n",
    "        data = get_page_reviews(soup)\n",
    "        df = pd.DataFrame(data)\n",
    "        # Save the DataFrame to a CSV file\n",
    "        df.to_csv(f\"{hotel[0]}.csv\", mode='a', index=False)\n",
    "\n",
    "# List to hold found hotels\n",
    "hotel_list: list[list] = []\n",
    "\n",
    "with open('hotel_list_3.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        hotel_list.append(row)\n",
    "\n",
    "# loop thru the hotel list to get the reviews\n",
    "for hotel in hotel_list:    \n",
    "    if len(hotel) > 2:\n",
    "        temp_hotel = [''.join(hotel[:-1]).replace(',', ' '), hotel[-1]]\n",
    "    else:\n",
    "        temp_hotel = hotel\n",
    "\n",
    "    get_hotel_reviews(temp_hotel)\n",
    "    \n",
    "    hotel_count += 1\n",
    "\n",
    "# Close the web driver\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
